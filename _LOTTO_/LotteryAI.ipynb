{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMuZhX3puT9YwrHpZwXaxnb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install text2art"],"metadata":{"id":"Sz2_yK6eN5J5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install adversarial-robustness-toolbox"],"metadata":{"id":"mIK7bc_nOPqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install matplotlib==3.1.3"],"metadata":{"id":"RuWAyVnAOc2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install art"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHj4KGfLQJqh","executionInfo":{"status":"ok","timestamp":1702551932332,"user_tz":180,"elapsed":16430,"user":{"displayName":"dig dant","userId":"01774453568763058657"}},"outputId":"ebe6bbae-9920-4b8a-ec82-6a98094bd068"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting art\n","  Downloading art-6.1-py3-none-any.whl (599 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.8/599.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: art\n","Successfully installed art-6.1\n"]}]},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","from art import text2art\n","from art import *\n","\n","# Function to print the introduction of the program\n","def print_intro():\n","    # Generate ASCII art with the text \"LotteryAi\"\n","    ascii_art = text2art(\"LotteryAi\")\n","    # Print the introduction and ASCII art\n","    print(\"============================================================\")\n","    print(\"LotteryAi\")\n","    print(\"Created by: Corvus Codex\")\n","    print(\"Github: https://github.com/CorvusCodex/\")\n","    print(\"Licence : MIT License\")\n","    print(\"Support my work:\")\n","    print(\"BTC: bc1q7wth254atug2p4v9j3krk9kauc0ehys2u8tgg3\")\n","    print(\"ETH & BNB: 0x68B6D33Ad1A3e0aFaDA60d6ADf8594601BE492F0\")\n","    print(\"Buy me a coffee: https://www.buymeacoffee.com/CorvusCodex\")\n","    print(\"============================================================\")\n","    print(ascii_art)\n","    print(\"Lottery prediction artificial intelligence\")\n","\n","# Function to load data from a file and preprocess it\n","def load_data():\n","    # Load data from file, ignoring white spaces and accepting unlimited length numbers\n","    data = np.genfromtxt('data.txt', delimiter=',', dtype=int)\n","    # Replace all -1 values with 0\n","    data[data == -1] = 0\n","    # Split data into training and validation sets\n","    train_data = data[:int(0.8*len(data))]\n","    val_data = data[int(0.8*len(data)):]\n","    # Get the maximum value in the data\n","    max_value = np.max(data)\n","    return train_data, val_data, max_value\n","\n","# Function to create the model\n","def create_model(num_features, max_value):\n","    # Create a sequential model\n","    model = keras.Sequential()\n","    # Add an Embedding layer, LSTM layer, and Dense layer to the model\n","    model.add(layers.Embedding(input_dim=max_value+1, output_dim=64))\n","    model.add(layers.LSTM(256))\n","    model.add(layers.Dense(num_features, activation='softmax'))\n","    # Compile the model with categorical crossentropy loss, adam optimizer, and accuracy metric\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","# Function to train the model\n","def train_model(model, train_data, val_data):\n","    # Fit the model on the training data and validate on the validation data for 100 epochs\n","    history = model.fit(train_data, train_data, validation_data=(val_data, val_data), epochs=100)\n","\n","# Function to predict numbers using the trained model\n","def predict_numbers(model, val_data, num_features):\n","    # Predict on the validation data using the model\n","    predictions = model.predict(val_data)\n","    # Get the indices of the top 'num_features' predictions for each sample in validation data\n","    indices = np.argsort(predictions, axis=1)[:, -num_features:]\n","    # Get the predicted numbers using these indices from validation data\n","    predicted_numbers = np.take_along_axis(val_data, indices, axis=1)\n","    return predicted_numbers\n","\n","# Function to print the predicted numbers\n","def print_predicted_numbers(predicted_numbers):\n","   # Print a separator line and \"Predicted Numbers:\"\n","   print(\"============================================================\")\n","   print(\"Predicted Numbers:\")\n","   # Print only the first row of predicted numbers\n","   print(', '.join(map(str, predicted_numbers[0])))\n","   print(\"============================================================\")\n","   print(\"Buy me a coffee: https://www.buymeacoffee.com/CorvusCodex\")\n","   print(\"============================================================\")\n","\n","# Main function to run everything\n","def main():\n","   # Print introduction of program\n","   print_intro()\n","\n","   # Load and preprocess data\n","   train_data, val_data, max_value = load_data()\n","\n","   # Get number of features from training data\n","   num_features = train_data.shape[1]\n","\n","   # Create and compile model\n","   model = create_model(num_features, max_value)\n","\n","   # Train model\n","   train_model(model, train_data, val_data)\n","\n","   # Predict numbers using trained model\n","   predicted_numbers = predict_numbers(model, val_data, num_features)\n","\n","   # Print predicted numbers\n","   print_predicted_numbers(predicted_numbers)\n","\n","# Run main function if this script is run directly (not imported as a module)\n","if __name__ == \"__main__\":\n","   main()"],"metadata":{"id":"yfYjMUnmIilX","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"error","timestamp":1702551910537,"user_tz":180,"elapsed":4774,"user":{"displayName":"dig dant","userId":"01774453568763058657"}},"outputId":"01953329-ec9b-4981-a8a2-43d0d9a0ec9d"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5ccc4fdd87c5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext2art\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'art'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["!p"],"metadata":{"id":"_d-rzybyNxxf"},"execution_count":null,"outputs":[]}]}